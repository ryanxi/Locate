//fSensorFile format: Timestamp in nanosecond, lacc0, lacc1, lacc2, ori0, ori1, ori2, (LONG, float*6)
//fWaveFile format: (44100Hz) 16bit wave, Big endian
package com.hwc.wavedirection;

import java.io.BufferedOutputStream;
import java.io.DataOutputStream;
import java.io.File;
import java.io.FileNotFoundException;
import java.io.FileOutputStream;
import java.io.IOException;
import java.lang.ref.PhantomReference;
import java.sql.Timestamp;
import java.text.SimpleDateFormat;
import java.util.ArrayList;
import java.util.Date;
import java.util.concurrent.ArrayBlockingQueue;
import java.util.concurrent.BlockingQueue;

import android.opengl.Matrix;
import android.os.Bundle;
import android.os.Environment;
import android.os.SystemClock;
import android.app.Activity;
import android.view.KeyEvent;
import android.view.Menu;
import android.view.SurfaceView;
import android.media.AudioFormat;
import android.media.AudioManager;
import android.media.AudioRecord;
import android.media.AudioTrack;
import android.media.MediaRecorder;
import android.view.View;
import android.widget.Button;
import android.widget.SeekBar;
import android.widget.TextView;
import android.graphics.Canvas;
import android.graphics.Color;
import android.graphics.Paint;
import android.graphics.Rect;
import android.hardware.Sensor;
import android.hardware.SensorEvent;
import android.hardware.SensorEventListener;
import android.hardware.SensorManager;

public class Wave2Direction extends Activity implements SensorEventListener {
	public static double mean(double[] m) {
	    double sum = 0;
	    for (int i = 0; i < m.length; i++) {
	        sum += m[i];
	    }
	    return sum / m.length;
	}
	public class BPFThread extends Thread {
		public void run() {
			//init BPF data
			filterwave.clear();
			
			FilterDesign fd = new FilterDesign();
			double fs = 44100;
			ButtordResult br = fd.buttord(18500*2/fs, 19500*2/fs,18000*2/fs, 20000*2/fs, 10, 40);
			BiResult bir = fd.butter(br.n, br.wnl, br.wnh);
			int size=bir.a.length;
			double[] a=new double[size];
			double[] b=bir.b;
			for (int i=0;i<size;i++)
				a[i]=bir.a[size-i-1];
			double uni=a[size-1];
			for (int i=0;i<size;i++)
			{
				a[i]/=uni;
				b[i]/=uni;
			}
			//TODO: the size is set to 15, but will change when a and b change
			double[] xwindow=new double[size];
			double[] ywindow=new double[size];
			double[] buffer=new double[buffersize]; //output
			double[] wavebuffer;
			try {
				wavebuffer=wavedata.take();
			} catch (InterruptedException e) {
				// TODO Auto-generated catch block
				e.printStackTrace();
				return;
			}

			int i=0;
			int j=0;
			double tmpy=0;
			while(isRecording)
			{
				int outputindex=i%buffersize;
//				currentphase=i;

				xwindow[size-1]=wavebuffer[outputindex];
				ywindow[size-1]=0;
				buffer[outputindex]=0;
				tmpy=0;
				for(j=0;j<size-1;j++)
				{
					tmpy+=b[j]*xwindow[j]-a[j]*ywindow[j];
					ywindow[j]=ywindow[j+1];
					xwindow[j]=xwindow[j+1];
				}
				tmpy+=b[size-1]*xwindow[size-1];
				ywindow[size-2]=tmpy;
				buffer[outputindex]=tmpy;
//				currentphase=tmpy;
				
//				try {
//				Audiodataoutputstream.writeDouble(tmpy);
//			} catch (IOException e1) {
//				// TODO Auto-generated catch block
//				e1.printStackTrace();
//			}
				i++;
				if(i%buffersize==0)
				{
					int tmpsize=i/buffersize;
					try {
						wavebuffer=wavedata.take();
					} catch (InterruptedException e) {
						// TODO Auto-generated catch block
						e.printStackTrace();
						return;
					}

					try {
						filterwave.put(buffer);
					} catch (InterruptedException e) {
						// TODO Auto-generated catch block
						e.printStackTrace();
					}
					buffer = new double[buffersize];
				}
					
			}

		}
//		public void run() {
//			//init BPF data
//			filterwave.clear();
//			
//			double[] a=new double[15];
//			double[] b=new double[15];
//			a[14]=0;
//			a[13]=11.7721066157362;
//			a[12]=65.3077589324416;
//			a[11]=226.185657446171;
//			a[10]=546.150036171117;
//			a[9]=972.316446369654;
//			a[8]=1315.93086786799;
//			a[7]=1375.24519518761;
//			a[6]=1115.19286352373;
//			a[5]=698.306288807843;
//			a[4]=332.415854579607;
//			a[3]=116.676646053042;
//			a[2]=28.5536436089761;
//			a[1]=4.36288610741819;
//			a[0]=0.314203960928239;
//			b[14]=3.34338905570474e-07;
//			b[13]=0;
//			b[12]=-2.34037233899332e-06;
//			b[11]=0;
//			b[10]=7.02111701697995e-06;
//			b[9]=0;
//			b[8]=-1.17018616949666e-05;
//			b[7]=0;
//			b[6]=1.17018616949666e-05;
//			b[5]=0;
//			b[4]=-7.02111701697995e-06;
//			b[3]=0;
//			b[2]=2.34037233899332e-06;
//			b[1]=0;
//			b[0]=-3.34338905570474e-07;
//			//TODO: the size is set to 15, but will change when a and b change
//			double[] xwindow=new double[15];
//			double[] ywindow=new double[15];
//			double[] buffer=new double[buffersize]; //output
//			double[] wavebuffer;
//			try {
//				wavebuffer=wavedata.take();
//			} catch (InterruptedException e) {
//				// TODO Auto-generated catch block
//				e.printStackTrace();
//				return;
//			}
//
//			int i=0;
//			int j=0;
//			double tmpy=0;
//			while(isRecording)
//			{
//				int outputindex=i%buffersize;
////				currentphase=i;
//
//				xwindow[14]=wavebuffer[outputindex];
//				ywindow[14]=0;
//				buffer[outputindex]=0;
//				tmpy=0;
//				for(j=0;j<14;j++)
//				{
//					tmpy+=b[j]*xwindow[j]-a[j]*ywindow[j];
//					ywindow[j]=ywindow[j+1];
//					xwindow[j]=xwindow[j+1];
//				}
//				tmpy+=b[14]*xwindow[14];
//				ywindow[13]=tmpy;
//				buffer[outputindex]=tmpy;
////				currentphase=tmpy;
//				
////				try {
////				Audiodataoutputstream.writeDouble(tmpy);
////			} catch (IOException e1) {
////				// TODO Auto-generated catch block
////				e1.printStackTrace();
////			}
//				i++;
//				if(i%buffersize==0)
//				{
//					int tmpsize=i/buffersize;
//					try {
//						wavebuffer=wavedata.take();
//					} catch (InterruptedException e) {
//						// TODO Auto-generated catch block
//						e.printStackTrace();
//						return;
//					}
//
//					try {
//						filterwave.put(buffer);
//					} catch (InterruptedException e) {
//						// TODO Auto-generated catch block
//						e.printStackTrace();
//					}
//					buffer = new double[buffersize];
//				}
//					
//			}
//
//		}
	}
	public class AGCThread extends Thread {
		public void run() {
			//init agcdata
			agcwave.clear();
			
			final int meanlength=11;
			final double alpha=0.9;
			final int R=1;
			
			double A=1;
			double[] buffer=new double[buffersize]; //output
			int i=0;
			double[] filterbuffer;
			
			try {
				filterbuffer=filterwave.take();
			} catch (InterruptedException e1) {
				// TODO Auto-generated catch block
				e1.printStackTrace();
				return;
			}

			double[] meanbuf=new double[meanlength];
			double[] readbuf=new double[meanlength];
			double read=0;
			for (i=0;i<meanlength;i++)
			{
				read=filterbuffer[i];
				readbuf[i]=read;
			    meanbuf[i]=Math.abs(read);
			}
			i=0;
			while(isRecording)
			{
				int outputindex=i%buffersize;
//				buffer[outputindex]=filterbuffer[outputindex]*A;
//				buffer[i%buffersize]=readbuf[i%meanlength]*A;
				double result=readbuf[i%meanlength]*A;
				
//				if(result>1.5)
//					result=1.5;
//				if(result<-1.5)
//					result=-1.5;
				
				
				buffer[i%buffersize]=result;
//				try {
//					int k=i;
//					Audiodataoutputstream.writeDouble(buffer[outputindex]);
//				} catch (IOException e1) {
//					// TODO Auto-generated catch block
//					e1.printStackTrace();
//				}
				
//				double ARNT=mean(meanbuf);
//				A=A*(1-alpha*mean(meanbuf))+alpha*R;
				A=Math.exp(Math.log(A)*(1-alpha)-alpha*Math.log(mean(meanbuf)/R));

				if((i+meanlength)%buffersize==0)
				{		
					try {
						filterbuffer=filterwave.take();
					} catch (InterruptedException e) {
						// TODO Auto-generated catch block
						e.printStackTrace();
						return;
					}
				}
				read=filterbuffer[(i+meanlength)%buffersize];
				meanbuf[i%meanlength]=Math.abs(read);
				readbuf[i%meanlength]=read;
				i++;
				if(i%buffersize==0)
					try {
						agcwave.put(buffer);
						buffer = new double[buffersize];
					} catch (InterruptedException e) {
						// TODO Auto-generated catch block
						e.printStackTrace();
					}
			}
		}
	}

	public class PLLThread extends Thread {
		public void run() {
			//init 
			theta.clear();
			
			final int meanlength=11;
//			final double mu=0.08;
			final double mu=0.40;
			double fc=19000;
			double fliph[]=new double[11];
			final double pi=3.1415926535;
			final double Ts=1/44100.0;
			fliph[0]=0.246942129113388;
			fliph[1]=0.00262959944057275;
			fliph[2]=0.00217401867197993;
			fliph[3]=0.00224742173595086;
			fliph[4]=0.00242199262250945;
			fliph[5]=0.00247578810967912;
			fliph[6]=0.00242199262250945;
			fliph[7]=0.00224742173595086;
			fliph[8]=0.00217401867197993;
			fliph[9]=0.00262959944057275;
			fliph[10]=0.246942129113388;
			
			double[] buffer=new double[buffersize]; //output
			buffer[0]=2;
			int i=0;
			double[] z=new double[11];
//			int totalsize=wavesize-meanlength-2;
			double[] agcbuffer;
			//double[] agcbuffer=agcwave.get(0);//input
			
			try {
				agcbuffer=agcwave.take();
			} catch (InterruptedException e1) {
				// TODO Auto-generated catch block
				e1.printStackTrace();
				return;
			}
//			while(agcwave.isEmpty())
//				SystemClock.sleep(sleeptime);
//			synchronized (agcwave) {
//				agcbuffer=agcwave.get(0);
//			}
			while (isRecording)
			{
				double update=0;

				for (int j=0;j<10;j++)
				{
					z[j]=z[j+1];
					update+=z[j]*fliph[j];
				}
				double tmp=buffer[i%buffersize];
				z[10]=agcbuffer[i%buffersize]*Math.sin(2*pi*fc*Ts*(i+1)+tmp);
				update+=z[10]*fliph[10];
//				if(i%100000==0)
//					tvphase.setText("aa");

					
				i++;
				if(i%buffersize==0)
				{
					int tmpsize=i/buffersize;
					
					try {
						agcbuffer=agcwave.take();
					} catch (InterruptedException e) {
						// TODO Auto-generated catch block
						e.printStackTrace();
						return;
					}
//					while (agcwave.size()<=tmpsize)
//						SystemClock.sleep(sleeptime);
//					synchronized (agcwave) {
//						agcbuffer=agcwave.get(tmpsize);
//					}
					//agcbuffer=agcwave.get(i/buffersize);
					try {
						theta.put(buffer);
					} catch (InterruptedException e) {
						// TODO Auto-generated catch block
						e.printStackTrace();
					}
//					synchronized (theta) {
//						theta.add(buffer);
//					}
					buffer = new double[buffersize];

//					
				}

//				try {
//				Audiodataoutputstream.writeDouble(update);
//			} catch (IOException e) {
//				// TODO Auto-generated catch block
//				e.printStackTrace();
//			}
				
				if(update>0.15)
					update=0.15;
				if(update<-0.15)
					update=-0.15;
				
				buffer[i%buffersize]=tmp-mu*update;
//				globalangle=tmp*5;

			}
			
		}
	}

	
	public class ProcessPhase extends Thread {
		public void run(){
			double[] buffer;
			while(true)
			{
				try {
					buffer=theta.take();
				} catch (InterruptedException e) {
					// TODO Auto-generated catch block
					e.printStackTrace();
					return;
				}
				for (int i=0;i<buffersize;i++)
				{
					currentphase=buffer[i];
					drawpoint=buffer[i]*5;
					
					
					try {
						Audiodataoutputstream.writeDouble(currentphase);
					} catch (IOException e) {
						// TODO Auto-generated catch block
						e.printStackTrace();
					}
				}
			}
			
		}
	}

	Button btnStart, btnStop, btnExit;
	TextView tvaccx,tvaccy,tvaccz;
	double currentphase=0;
	float tmpx,tmpy,tmpz;
	SurfaceView sfv_soundwave;
	SeekBar skbVolume;// 调节音量
	boolean isRecording = false;// 是否录放的标记
    int settextcount=0;
    int showtextperiod=20;
    
	// 参数调整
    static final long sleeptime=10;
	static final int configAccelerameterRate = 500; // the desired delay between events in microsecond
	static final int frequency = 44100;
	static final int channelinConfiguration = AudioFormat.CHANNEL_IN_MONO;
	static final int channeloutConfiguration = AudioFormat.CHANNEL_OUT_MONO;
	static final int audioEncoding = AudioFormat.ENCODING_PCM_16BIT;
	static final String filenameWave="wave.dat";
	static final String filenameSensor="sensor.dat";

	String DirnameHWCphone="/mnt/sdcard/hwcWaveSample/";

	// draw wave 参数
	int rateX = 16;
	int rateY = 8;
	int baseLine = 0;
	static final int xMax = 16;// X轴缩小比例最大值,X轴数据量巨大，容易产生刷新延时
	static final int xMin = 8;// X轴缩小比例最小值
	static final int yMax = 10;// Y轴缩小比例最大值
	static final int yMin = 1;// Y轴缩小比例最小值
	
	
	static final int buffersize= 4096 ;
	static final int queuesize=3;
	BlockingQueue<double[]> wavedata =new ArrayBlockingQueue<double[]>(queuesize);
	BlockingQueue<double[]> filterwave =new ArrayBlockingQueue<double[]>(queuesize);
	BlockingQueue<double[]> agcwave =new ArrayBlockingQueue<double[]>(queuesize);
	BlockingQueue<double[]> theta =new ArrayBlockingQueue<double[]>(queuesize);
//	ArrayList<double[]> wavedata = new ArrayList<double[]>();
//	ArrayList<double[]> filterwave = new ArrayList<double[]>();
//	ArrayList<double[]> agcwave = new ArrayList<double[]>();
//	ArrayList<double[]> theta = new ArrayList<double[]>();
	int wavesize=0;
	
	private ArrayList<short[]> inBuf = new ArrayList<short[]>();
	private ArrayList<short[]> mAudioData = new ArrayList<short[]>();
	Paint mPaint;

	int  playBufSize;
	AudioRecord audioRecord;
	AudioTrack audioTrack;

	SensorManager sensorManager;
	public String directoryName;
//	public FileOutputStream fWaveRecord;
//	public RecordAudioThread recordThread;
	public DrawWaveThread drawThread;
	public String fulldirectoryName;
	public String fullFilenameWave;

	public FileOutputStream fWaveRecord;
	public BufferedOutputStream fBufferWaveRecord;
	public DataOutputStream Audiodataoutputstream;
	public String fullFilenameSensor;
	public FileOutputStream fSensorRecord;
	public BufferedOutputStream fBufferSensorRecord;
	public DataOutputStream Sensordataoutputstream;
//	public long sensorRecordtime;
//	private float[] accValue=new float[3];
	private float[] rotateValue=new float[3];
	
//	private float[] magValue=new float[3];
	private boolean iscounting=false;
	private int minbuffersize;
	private TextView tvphase;
//	public long audiorecordtime;
	private double drawpoint;
	private long sensorRecordtime;
	private long audioRecordtime=0;
	
	
	

	@Override
	public void onCreate(Bundle savedInstanceState) {

		super.onCreate(savedInstanceState);
		setContentView(R.layout.activity_wave2_direction);
		DirnameHWCphone=Environment.getExternalStorageDirectory().getPath()+"/hwcWaveSample";
		File destDir= new File(DirnameHWCphone);
		if (!destDir.exists()) {
			destDir.mkdirs();
		}
		// Audio configuration
		minbuffersize = AudioRecord.getMinBufferSize(frequency,
				channelinConfiguration, audioEncoding);

		playBufSize = AudioTrack.getMinBufferSize(frequency,
				channeloutConfiguration, audioEncoding);
		// -----------------------------------------
		audioRecord = new AudioRecord(MediaRecorder.AudioSource.MIC, frequency,
				channelinConfiguration, audioEncoding, buffersize);

		audioTrack = new AudioTrack(AudioManager.STREAM_MUSIC, frequency,
				channeloutConfiguration, audioEncoding, playBufSize,
				AudioTrack.MODE_STREAM);
		// ------------------------------------------
		btnStart = (Button) this.findViewById(R.id.button_Start);
		btnStart.setOnClickListener(new ClickEvent());
		tvaccx=(TextView) this.findViewById(R.id.textaccx);
		tvaccy=(TextView) this.findViewById(R.id.textaccy);
		tvaccz=(TextView) this.findViewById(R.id.textaccz);
		tvphase=(TextView) this.findViewById(R.id.textPhase);
		

		// Sensor configuration
		sensorManager = (SensorManager) getSystemService(SENSOR_SERVICE);
		//TODO set gravity
//		SensorManager.gr;
//		sensorManager
//				.registerListener(Wave2Direction.this, sensorManager
//						.getDefaultSensor(Sensor.TYPE_ACCELEROMETER),
//						configAccelerameterRate);
//		sensorManager
//		.registerListener(Wave2Direction.this, sensorManager
//				.getDefaultSensor(Sensor.TYPE_MAGNETIC_FIELD),
//				configAccelerameterRate);
//		sensorManager
//		.registerListener(Wave2Direction.this, sensorManager
//				.getDefaultSensor(Sensor.TYPE_ROTATION_VECTOR),
//				configAccelerameterRate);
//		sensorManager
//		.registerListener(Wave2Direction.this, sensorManager
//				.getDefaultSensor(Sensor.TYPE_LINEAR_ACCELERATION),
//				configAccelerameterRate);
		// SoundWave surface
		sfv_soundwave = (SurfaceView) this
				.findViewById(R.id.surfaceView_soundwave);
		mPaint = new Paint();
		mPaint.setColor(Color.GREEN);// 画笔为绿色
		mPaint.setStrokeWidth(1);// 设置画笔粗细
//		aaaa=new BlockingQueue<double[]>(40);
//		recordThread=new RecordAudioThread();
//		drawThread=new DrawWaveThread(sfv_soundwave, mPaint);

	}

	@Override
	public boolean onCreateOptionsMenu(Menu menu) {
		getMenuInflater().inflate(R.menu.activity_wave2_direction, menu);
		return true;
	}

	@Override
	protected void onDestroy() {
		super.onDestroy();
		android.os.Process.killProcess(android.os.Process.myPid());
	}

	public void onAccuracyChanged(Sensor sensor, int accuracy) {

	}


	@Override
	public boolean onKeyDown(int keyCode, KeyEvent event) {
		if (keyCode == KeyEvent.KEYCODE_BACK && event.getRepeatCount() == 0) {

			isRecording = false;
			inBuf.clear();
			SystemClock.sleep(300);
			this.finish();
			return false;
		}
		return false;
	}
	
    @Override
    public void onSensorChanged(SensorEvent event) {
    	if (!isRecording)
    		return;
//      if(!iscounting)
//    	  iscounting=true;
    	
//    	TODO: maintaining iscounting is click the button again
      if(!iscounting)
      {
    	  if(event.timestamp<audioRecordtime||audioRecordtime==0)
    		  return;
    	  else
    	  {
    		  sensorRecordtime=event.timestamp;
    		  iscounting=true;
    	  }
    	  
      }

//	  sensorRecordtime=sensorRecordtime;

      if (event.sensor.getType() == Sensor.TYPE_LINEAR_ACCELERATION ){
    	float[] laccValue=new float[4];
    	float[] RotationMatrix= new float[16];
		float[] RotationMatrixbar= new float[16];
		float[] matrixtrans= new float[16];
		float[] outputvalue =new float[4];
  		laccValue[0]=event.values[0];
  		laccValue[1]=event.values[1];
  		laccValue[2]=event.values[2];
  		laccValue[3]=1;
  		
    	float time = (event.timestamp-sensorRecordtime)*1.0f/1000000000.0f;
		SensorManager.getRotationMatrixFromVector(RotationMatrix , rotateValue);

		Matrix.transposeM(matrixtrans, 0, RotationMatrix, 0);
//		Matrix.invertM(RotationMatrixbar,0,matrixtrans,0);
		Matrix.multiplyMV(outputvalue, 0, matrixtrans, 0, laccValue, 0);
//		outputvalue[0]=event.values[0];
//		outputvalue[1]=event.values[1];
//		outputvalue[2]=event.values[2];
		

//		float[] testvector=new float[4];
//		float[] testout=new float[4];
//		testvector[0]=1;
//		Matrix.multiplyMV(testout, 0, RotationMatrixbar, 0, testvector, 0);
//		globalangle=Math.atan(testout[0]/testout[1])*400/3.14;
		
		
//		globalangle=10*Math.sqrt(outputvalue[0]*outputvalue[0]+outputvalue[1]*outputvalue[1]+outputvalue[2]*outputvalue[2]);
//		globalangle=1*Math.sqrt(laccValue[0]*laccValue[0]+laccValue[1]*laccValue[1]+laccValue[2]*laccValue[2]);
//		drawpoint=outputvalue[1]*10;
//		globalangle=rotateValue[0]*1000;
//		globalangle=Math.atan(outputvalue[0]/outputvalue[1])*400/3.14;
		
		try {
			Sensordataoutputstream.writeFloat(time);
			Sensordataoutputstream.writeFloat(outputvalue[0]);
			Sensordataoutputstream.writeFloat(outputvalue[1]);
			Sensordataoutputstream.writeFloat(outputvalue[2]);

			//setText:
			settextcount++;
			float mean=100.0f;
			tmpx=(outputvalue[0]+(mean-1)*tmpx)/mean;
			tmpy=(outputvalue[1]+(mean-1)*tmpy)/mean;
			tmpz=(outputvalue[2]+(mean-1)*tmpz)/mean;
			if (settextcount%showtextperiod==0)
			{
				tvaccx.setText(String.format("%1$,.5f",tmpx));
				tvaccy.setText(String.format("%1$,.5f",tmpy));
				tvaccz.setText(String.format("%1$,.5f",rotateValue[2]));
//				tvaccz.setText(String.format("%1$,.5f",(sensorRecordtime-audioRecordtime)*0.000000001f));
//		    	tvaccz.setText(String.format("%1$,.5f",Math.atan(tmpx/tmpy)*180/3.14));
				tvphase.setText("   "+String.format("%1$,.2f",currentphase*340/190/2/3.1415)+"cm");
//		    	tvphase.setText(String.valueOf(currentphase));
			}
		} catch (IOException e) {
			// TODO Auto-generated catch block
			e.printStackTrace();
		}
      }
    	
      else if (event.sensor.getType() == Sensor.TYPE_ROTATION_VECTOR ){
    	  rotateValue[0]=event.values[0];
    	  rotateValue[1]=event.values[1];
    	  rotateValue[2]=event.values[2];
//    	  rotateValue[3]=event.values[3];
      }
    	return;
    }


	class ClickEvent implements View.OnClickListener {

		@Override
		public void onClick(View v) {
			if (v == btnStart) {
				if (isRecording == false) {
					sensorManager
					.registerListener(Wave2Direction.this, sensorManager
							.getDefaultSensor(Sensor.TYPE_ROTATION_VECTOR),
							configAccelerameterRate);
					sensorManager
					.registerListener(Wave2Direction.this, sensorManager
							.getDefaultSensor(Sensor.TYPE_LINEAR_ACCELERATION),
							configAccelerameterRate);
//					sensorManager
//					.registerListener(Wave2Direction.this, sensorManager
//							.getDefaultSensor(Sensor.TYPE_ACCELEROMETER),
//							configAccelerameterRate);
//					prepare the filename
					directoryName=new SimpleDateFormat("MM-dd--HH_mm_ss").format(new Date(System.currentTimeMillis()));
					fulldirectoryName=DirnameHWCphone+"/"+directoryName;
					fullFilenameWave=fulldirectoryName+"/"+filenameWave;
					fullFilenameSensor=fulldirectoryName+"/"+filenameSensor;
//					record sound wave to file 
					File destDir= new File(fulldirectoryName);
					if (!destDir.exists()) {
						destDir.mkdirs();
					}
					try {
						fWaveRecord = new FileOutputStream(fullFilenameWave);
						fBufferWaveRecord=new BufferedOutputStream(fWaveRecord);
						Audiodataoutputstream = new DataOutputStream(fBufferWaveRecord);
					} catch (FileNotFoundException e) {
						// TODO Auto-generated catch block
						e.printStackTrace();
					}
//					record acc X,Y,Z to file
					try {
						fSensorRecord = new FileOutputStream(fullFilenameSensor);
						fBufferSensorRecord=new BufferedOutputStream(fSensorRecord);
						Sensordataoutputstream = new DataOutputStream(fBufferSensorRecord);
					} catch (FileNotFoundException e) {
						// TODO Auto-generated catch block
						e.printStackTrace();
					}
//					start recording
					//recordStarttime=System.nanoTime();
					isRecording = true;
					new RecordAudioThread().start();// 开一条线程边录边放
					new DrawWaveThread(sfv_soundwave, mPaint).start();
					new BPFThread().start();
					new AGCThread().start();
					new PLLThread().start();
					new ProcessPhase().start();
					btnStart.setText("Already Started, Click to Stop");
				} else {
//					stop everything
					
					isRecording = false;
					iscounting=false;
//					SystemClock.sleep(600);
//					for (int i=0;i<mAudioData.size();i++){
//						short[] tmp=mAudioData.get(i);
//
//						for (int j=0;j<tmp.length;j++)
//
//							try {
//								
//								Audiodataoutputstream.writeShort(tmp[j]);
//							} catch (IOException e) {
//								// TODO Auto-generated catch block
//								e.printStackTrace();
//							}
//					}
					try {
						Audiodataoutputstream.close();
						fWaveRecord.close();
						Sensordataoutputstream.close();
						fSensorRecord.close();
					} catch (IOException e) {
						// TODO Auto-generated catch block
						e.printStackTrace();
					}
					mAudioData.clear();
					inBuf.clear();
//					SystemClock.sleep(600);	
					sensorManager.unregisterListener(Wave2Direction.this);
					btnStart.setText("Already Stopped, Click to Start");
				}
			} else if (v == btnStop) {
				isRecording = false;
			} else if (v == btnExit) {
				isRecording = false;
				Wave2Direction.this.finish();
			}
		}
	}

	class RecordAudioThread extends Thread {
		



		public void run() {
				//init wavedata
				wavesize=0;
				wavedata.clear();
			
//				long datetime=new Date().getTime()*1000000;
				short[] buffer = new short[minbuffersize];
//				audioRecordtime=System.nanoTime();
				audioRecord.startRecording();// 开始录制
				audioRecordtime=new Timestamp(System.currentTimeMillis()).getTime()*1000000;
				
//				audiorecordtime=System.nanoTime()-datetime;
				double[] wavebuffer=new double[buffersize];
				while (isRecording) {
					// 从MIC保存数据到缓冲区
					int bufferReadResult = audioRecord.read(buffer, 0,
							minbuffersize);
					short[] tmpBuf = new short[bufferReadResult];
					System.arraycopy(buffer, 0, tmpBuf, 0, bufferReadResult);
					for (int i=0;i<bufferReadResult;i++)
					{
//						try {
//							Audiodataoutputstream.writeShort(tmpBuf[i]);
//						} catch (IOException e1) {
//							// TODO Auto-generated catch block
//							e1.printStackTrace();
//						}
						wavebuffer[wavesize%buffersize]=tmpBuf[i]/65536.0;//TODO: 1.0-->65536.0
						wavesize++;
						if(wavesize%buffersize==0)
							try {
								wavedata.put(wavebuffer);
								wavebuffer=new double[buffersize];
							} catch (InterruptedException e) {
								// TODO Auto-generated catch block
								e.printStackTrace();
							}
//							synchronized (wavebuffer) {
//								wavedata.add(wavebuffer);
//							}
							
					}
//					synchronized(tmpBuf){
//						mAudioData.add(tmpBuf);	
//					}
					synchronized (inBuf) {//
						inBuf.add(tmpBuf);// 添加数据
						// inBuf.clear();
					}
					// 写入数据即播放
					// audioTrack.write(tmpBuf, 0, tmpBuf.length);
				}
				// audioTrack.stop();
				audioRecord.stop();

		}

	};

	class DrawWaveThread extends Thread {
		private int oldX = 0;// 上次绘制的X坐标
		private int oldY = 0;// 上次绘制的Y坐标
		private SurfaceView sfv;// 画板
		private int X_index = 0;// 当前画图所在屏幕X轴的坐标
		private Paint mPaint;// 画笔
		private int drawindex;
		private short[] drawbuf;

		public DrawWaveThread(SurfaceView sfv, Paint mPaint) {
			this.sfv = sfv;
			this.mPaint = mPaint;
			drawbuf=new short[2000];
		}

		@SuppressWarnings("unchecked")
		public void run() {
			while (isRecording) {
				int drawlength=4;
				int length=sfv_soundwave.getWidth()/drawlength;
				drawbuf[drawindex%length]=(short) (-drawpoint*10);
				drawindex++;
//				SystemClock.sleep(1);
				SimpleDraw(0,drawbuf,rateY,baseLine);
//				ArrayList<short[]> buf = new ArrayList<short[]>();
//				synchronized (inBuf) {
//					if (inBuf.size() == 0)
//						continue;
//					buf = (ArrayList<short[]>) inBuf.clone();// 保存
//					inBuf.clear();// 清除
//				}
//				for (int i = 0; i < buf.size(); i++) {
//					short[] tmpBuf = buf.get(i);
//					if(i%2==0)
//						SimpleDraw(X_index, tmpBuf, rateY, baseLine);// 把缓冲区数据画出来
//					X_index = X_index + tmpBuf.length;
//					if (X_index > sfv.getWidth()) {
//						X_index = 0;
//					}
//				}
				
//				int i=0;
//				double[] buffer=new double[buffersize];
//				while(theta.size()<=i);
//				buffer=theta.get(i);
////				tvaccx.setText("a");
//				i++;
			}
		}

		/**
		 * 绘制指定区域
		 * 
		 * @param start
		 *            X轴开始的位置(全屏)
		 * @param buffer
		 *            缓冲区
		 * @param rate
		 *            Y轴数据缩小的比例
		 * @param baseLine
		 *            Y轴基线
		 */
		void SimpleDraw(int start, short[] buffer, int rate, int baseLine) {
			int drawlength=4;
			baseLine = sfv_soundwave.getHeight() / 2;
			if (start == 0)
				oldX = 0;
			Canvas canvas = sfv.getHolder().lockCanvas(
					new Rect(start, 0, start + buffer.length, sfv.getHeight()));// 关键:获取画布
			canvas.drawColor(Color.BLACK);// 清除背景
			int y;
			for (int i = 0; i < buffer.length; i++) {// 有多少画多少
//				if (i%2!=0)
//					continue;
				int x = i *drawlength+ start;
				y = buffer[i] / rate + baseLine;// 调节缩小比例，调节基准线

				canvas.drawLine(oldX, oldY, x, y, mPaint);
				oldX = x;
				oldY = y;
			}
			sfv.getHolder().unlockCanvasAndPost(canvas);// 解锁画布，提交画好的图像
		}
	}
	

}

//					fullFilenameAccX=fulldirectoryName+"/"+filenameAccX;
//					fullFilenameAccY=fulldirectoryName+"/"+filenameAccY;
//					fullFilenameAccZ=fulldirectoryName+"/"+filenameAccZ;